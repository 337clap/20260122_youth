import os
import random
from datetime import datetime, date, timedelta
from typing import Dict, Tuple

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt


# -----------------------------
# Files
# -----------------------------
BENCH_DEFAULT_PATH = "youth_digital_wellbeing_apps_cleaned.csv"
LOG_DEFAULT_PATH = "user_activity_log.csv"


# -----------------------------
# Content
# -----------------------------
EMOJI_BY_LEVEL = {"LOW": "ğŸŸ¢ğŸ™‚", "MEDIUM": "ğŸŸ¡ğŸ˜¯", "HIGH": "ğŸ”´ğŸ˜µâ€ğŸ’«"}
LABEL_KO = {"LOW": "ë‚®ìŒ", "MEDIUM": "ì£¼ì˜", "HIGH": "ìœ„í—˜"}

LEVEL_COPY = {
    "LOW": "ì¢‹ì€ íë¦„ì´ì—ìš”! ìœ ì§€í•˜ë©´ì„œ â€˜ì§§ì€ ì˜¤í”„â€™ë§Œ ìŠµê´€í™”í•˜ë©´ ë” ì¢‹ì•„ìš”.",
    "MEDIUM": "ì¡°ì ˆì´ í•„ìš”í•´ìš”. ì˜¤ëŠ˜ì€ ì˜¤í”„ ì‹œê°„ì„ â€˜ì¼ì •â€™ì²˜ëŸ¼ í™•ì •í•´ë³´ì„¸ìš”.",
    "HIGH": "ê³¼ì˜ì¡´ ìœ„í—˜ì´ ë†’ì•„ìš”. ì˜¤ëŠ˜ì€ â€˜ê°•ì œ ì˜¤í”„â€™ + ëŒ€ì²´ í™œë™ì„ ê¼­ ë¶™ì—¬ìš”.",
}

NON_DIGITAL_ACTIVITY_POOL = [
    "ì‚°ì±… 10ë¶„ ğŸš¶",
    "ìŠ¤íŠ¸ë ˆì¹­ 5ë¶„ ğŸ§˜",
    "ë¬¼ í•œ ì»µ ğŸ’§",
    "ì±… 10í˜ì´ì§€ ğŸ“–",
    "ëˆˆ ì‰¬ê¸° 2ë¶„(ë¨¼ ê³³ ë³´ê¸°) ğŸ‘€",
    "ë°© ì •ë¦¬ 5ë¶„ ğŸ§¹",
    "ì†ê¸€ì”¨ë¡œ ê°ì • í•œ ì¤„ âœï¸",
    "ê°€ë²¼ìš´ ìŠ¤ì¿¼íŠ¸ 15íšŒ ğŸ‹ï¸",
    "ìŒì•… ë“£ê³  ëˆˆ ê°ê¸° 5ë¶„ ğŸ§",
    "ê°„ì‹ ëŒ€ì‹  ê³¼ì¼ ğŸ",
    "ì¹œêµ¬/ê°€ì¡± ì•ˆë¶€ ë¬¸ì ğŸ’¬",
]

DIGITAL_SWITCH_MESSAGES = {
    "LOW": "ì˜¤ëŠ˜ë„ ì˜í•˜ê³  ìˆì–´ìš”! ğŸ“µâœ¨",
    "MEDIUM": "5~15ë¶„ë§Œ ì‰¬ì–´ë„ íš¨ê³¼ ì»¤ìš” ğŸ™‚ğŸ“µ",
    "HIGH": "ì§€ê¸ˆì€ â€˜ì˜¤í”„â€™ê°€ ì§„ì§œ ë„ì›€ë¼ìš”â€¦ ğŸ’¤ğŸ“µ",
}


# -----------------------------
# Benchmark (public data)
# -----------------------------
def load_csv_robust(path_or_bytes) -> pd.DataFrame:
    # Accept path or bytes
    encodings = ["utf-8-sig", "utf-8", "cp949"]
    if isinstance(path_or_bytes, (bytes, bytearray)):
        for enc in encodings:
            try:
                return pd.read_csv(pd.io.common.BytesIO(path_or_bytes), encoding=enc)
            except Exception:
                pass
        raise ValueError("CSV ì¸ì½”ë”©ì„ ì½ì§€ ëª»í–ˆì–´ìš”. utf-8/cp949ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        for enc in encodings:
            try:
                return pd.read_csv(path_or_bytes, encoding=enc)
            except Exception:
                pass
        raise FileNotFoundError(f"ë²¤ì¹˜ë§ˆí¬ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”: {path_or_bytes}")


def load_benchmark_df(uploaded) -> pd.DataFrame:
    if uploaded is not None:
        return load_csv_robust(uploaded.read())
    return load_csv_robust(BENCH_DEFAULT_PATH)


def compute_rates(df: pd.DataFrame) -> Dict[str, Dict[str, float]]:
    required = [
        "êµ¬ë¶„",
        "ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ì¡°ì‚¬ì¸ì›",
        "ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ìœ„í—˜ ì‚¬ìš©ìêµ°",
        "ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ì£¼ì˜ ì‚¬ìš©ìêµ°",
        "ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ì¡°ì‚¬ ì¸ì›",
        "ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ìœ„í—˜ ì‚¬ìš©ìêµ°",
        "ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ì£¼ì˜ ì‚¬ìš©ìêµ°",
    ]
    for c in required:
        if c not in df.columns:
            raise ValueError(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì»¬ëŸ¼ ëˆ„ë½: {c}")

    out = {}
    for _, r in df.iterrows():
        g = str(r["êµ¬ë¶„"]).strip()
        if g == "" or g.lower() == "nan":
            continue

        internet_n = float(r["ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ì¡°ì‚¬ì¸ì›"])
        phone_n = float(r["ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ì¡°ì‚¬ ì¸ì›"])

        internet_risk = float(r["ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ìœ„í—˜ ì‚¬ìš©ìêµ°"])
        internet_caution = float(r["ì¸í„°ë„· ê³¼ì˜ì¡´ í˜„í™©_ì£¼ì˜ ì‚¬ìš©ìêµ°"])

        phone_risk = float(r["ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ìœ„í—˜ ì‚¬ìš©ìêµ°"])
        phone_caution = float(r["ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ í˜„í™©_ì£¼ì˜ ì‚¬ìš©ìêµ°"])

        internet_rate = (internet_risk + internet_caution) / internet_n if internet_n > 0 else 0.0
        phone_rate = (phone_risk + phone_caution) / phone_n if phone_n > 0 else 0.0

        out[g] = {"internet_rate": internet_rate, "phone_rate": phone_rate}
    return out


# -----------------------------
# Personal Log (in-app data)
# -----------------------------
LOG_COLUMNS = [
    "date",            # YYYY-MM-DD
    "group",           # ì´ˆ4/ì¤‘1/ê³ 1 or user-selected
    "gender",          # ë‚¨/ì—¬
    "internet_min",    # int
    "phone_min",       # int
    "sleep_hours",     # float (optional)
    "stress_1_10",     # int (optional)
    "mood_1_10",       # int (optional)
    "note",            # str (optional)
]


def empty_log_df() -> pd.DataFrame:
    return pd.DataFrame(columns=LOG_COLUMNS)


def load_log_df(uploaded_log) -> pd.DataFrame:
    # priority: uploaded > local file > empty
    if uploaded_log is not None:
        df = load_csv_robust(uploaded_log.read())
        return normalize_log_df(df)
    if os.path.exists(LOG_DEFAULT_PATH):
        try:
            df = load_csv_robust(LOG_DEFAULT_PATH)
            return normalize_log_df(df)
        except Exception:
            return empty_log_df()
    return empty_log_df()


def normalize_log_df(df: pd.DataFrame) -> pd.DataFrame:
    # Ensure all needed columns exist
    for c in LOG_COLUMNS:
        if c not in df.columns:
            df[c] = np.nan
    df = df[LOG_COLUMNS].copy()

    # Types
    df["date"] = df["date"].astype(str)
    for c in ["internet_min", "phone_min"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    for c in ["sleep_hours"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    for c in ["stress_1_10", "mood_1_10"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # Drop obviously bad dates
    df = df[df["date"].str.len() >= 8]
    return df


def safe_save_log(df: pd.DataFrame) -> bool:
    # Streamlit CloudëŠ” íŒŒì¼ ì €ì¥ì´ íœ˜ë°œë  ìˆ˜ ìˆì–´ë„,
    # ì„¸ì…˜ ì¤‘ì—ëŠ” ì €ì¥ì´ ë˜ê³¤ í•©ë‹ˆë‹¤. ì‹¤íŒ¨í•˜ë©´ ë‹¤ìš´ë¡œë“œë¡œ ëŒ€ì²´.
    try:
        df.to_csv(LOG_DEFAULT_PATH, index=False, encoding="utf-8-sig")
        return True
    except Exception:
        return False


# -----------------------------
# Diagnosis logic (experience-first)
# -----------------------------
def base_score_from_minutes(total_min: int) -> float:
    # explainable piecewise mapping 0~100
    if total_min <= 60: return 15
    if total_min <= 90: return 25
    if total_min <= 120: return 35
    if total_min <= 180: return 50
    if total_min <= 240: return 65
    if total_min <= 300: return 78
    if total_min <= 360: return 88
    return 95


def benchmark_context_multiplier(group: str, gender: str, rates: Dict[str, Dict[str, float]]) -> float:
    # Gentle adjustment from benchmark prevalence (context only)
    if group in rates:
        p = (rates[group]["internet_rate"] + rates[group]["phone_rate"]) / 2.0
    else:
        p = np.mean([(v["internet_rate"] + v["phone_rate"]) / 2.0 for v in rates.values()]) if rates else 0.15

    p = float(np.clip(p, 0.05, 0.40))
    mult = 1.0 + (p - 0.10) * 0.7
    if gender == "ì—¬":
        mult *= 1.02  # tiny
    return float(np.clip(mult, 0.9, 1.2))


def decide_level(score: int) -> str:
    if score < 40: return "LOW"
    if score < 70: return "MEDIUM"
    return "HIGH"


def switch_off_plan(level: str, total_min: int) -> Tuple[int, int]:
    if level == "LOW":
        return (120, 10)
    if level == "MEDIUM":
        return (90, 15)
    # HIGH
    if total_min >= 360:
        return (45, 20)
    return (60, 20)


def recommend_activities(level: str) -> list:
    k = 3 if level == "LOW" else 4 if level == "MEDIUM" else 5
    return random.sample(NON_DIGITAL_ACTIVITY_POOL, k=min(k, len(NON_DIGITAL_ACTIVITY_POOL)))


def recommend_off_window(level: str, preferred_start_hour: int, preferred_end_hour: int) -> str:
    # Suggest a realistic "off block" in evening by default
    if level == "LOW":
        minutes = 15
    elif level == "MEDIUM":
        minutes = 30
    else:
        minutes = 45

    # Keep within window
    start = preferred_start_hour
    end = preferred_end_hour
    if end <= start:
        end = start + 2  # fallback

    # Put it near the end (before sleep)
    off_start = max(start, end - 2)
    off_end = min(end, off_start + 1)

    # Convert to times
    return f"{off_start:02d}:00 ~ {off_end:02d}:00 ì‚¬ì´ì— **{minutes}ë¶„ ì˜¤í”„ ë¸”ë¡** ì¶”ì²œ"


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="Digital Balance (ê³µê³µë°ì´í„°+ë‚´ ë¡œê·¸)", page_icon="ğŸ“µ", layout="centered")
st.title("ğŸ“µ Digital Balance")
st.caption("ê³µê³µë°ì´í„°(ë²¤ì¹˜ë§ˆí¬) + ë‚´ ê¸°ë¡(ë¡œê·¸)ë¡œ â€˜ì§„ì§œ ë°ì´í„° ê¸°ë°˜â€™ ë””ì§€í„¸ ì›°ë¹™ ì•±ì„ ë§Œë“­ë‹ˆë‹¤.")

with st.sidebar:
    st.header("1) ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°")
    bench_upload = st.file_uploader("youth_digital_wellbeing_apps_cleaned.csv ì—…ë¡œë“œ(ì„ íƒ)", type=["csv"])
    st.caption("ë ˆí¬ì— ê°™ì€ íŒŒì¼ì„ ì˜¬ë ¤ë‘ë©´ ì—…ë¡œë“œ ì—†ì´ ìë™ ë¡œë”©ë©ë‹ˆë‹¤.")

    st.divider()
    st.header("2) ë‚´ ë¡œê·¸ ë°ì´í„°")
    log_upload = st.file_uploader("ê¸°ì¡´ ë¡œê·¸ ì—…ë¡œë“œ(ì„ íƒ)", type=["csv"])
    st.caption("Streamlit CloudëŠ” ì €ì¥ì´ íœ˜ë°œë  ìˆ˜ ìˆì–´ìš”. ë¡œê·¸ëŠ” ë‚´ë ¤ë°›ì•„ ë³´ê´€í•˜ëŠ” ê±¸ ì¶”ì²œí•´ìš”.")

# Load data
try:
    bench_df = load_benchmark_df(bench_upload)
    bench_rates = compute_rates(bench_df)
except Exception as e:
    st.error(f"ë²¤ì¹˜ë§ˆí¬ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

log_df = load_log_df(log_upload)

tabs = st.tabs(["ğŸ§ª ì˜¤ëŠ˜ ì§„ë‹¨", "ğŸ“ˆ ì¶”ì„¸", "ğŸ—“ï¸ ì£¼ê°„ ë¦¬í¬íŠ¸", "âš™ï¸ ë°ì´í„°"])

# -----------------------------
# Tab 1: Today diagnosis + add log
# -----------------------------
with tabs[0]:
    st.subheader("ğŸ§ª ì˜¤ëŠ˜ì˜ ìœ„í—˜ ì§„ë‹¨ & ê¸°ë¡")
    col1, col2 = st.columns(2)

    with col1:
        group = st.selectbox("í•™ë…„/ì§‘ë‹¨(êµ¬ë¶„)", ["ì´ˆ4", "ì¤‘1", "ê³ 1"], index=1)
        gender = st.radio("ì„±ë³„", ["ë‚¨", "ì—¬"], horizontal=True)
        the_date = st.date_input("ë‚ ì§œ", value=date.today())

    with col2:
        internet_min = st.number_input("ì¸í„°ë„· ì‚¬ìš©(ë¶„)", min_value=0, max_value=24*60, value=120, step=5)
        phone_min = st.number_input("ìŠ¤ë§ˆíŠ¸í° ì‚¬ìš©(ë¶„)", min_value=0, max_value=24*60, value=180, step=5)

    st.markdown("**(ì„ íƒ) ì»¨ë””ì…˜ ì…ë ¥** â€” ì •í™•í•œ ì˜ˆì¸¡ ëª¨ë¸ì€ ì•„ë‹ˆì§€ë§Œ, â€˜ë‚´ ë³€í™”â€™ë¥¼ ê¸°ë¡í•˜ëŠ” ë° ë„ì›€ì´ ë¼ìš”.")
    c1, c2, c3 = st.columns(3)
    with c1:
        sleep_hours = st.number_input("ìˆ˜ë©´ì‹œê°„(ì‹œê°„)", min_value=0.0, max_value=16.0, value=7.0, step=0.5)
    with c2:
        stress = st.number_input("ìŠ¤íŠ¸ë ˆìŠ¤(1~10)", min_value=1, max_value=10, value=5, step=1)
    with c3:
        mood = st.number_input("ê¸°ë¶„(1~10)", min_value=1, max_value=10, value=6, step=1)

    note = st.text_input("ë©”ëª¨(ì„ íƒ)", placeholder="ì˜ˆ: ì‹œí—˜ê¸°ê°„ì´ë¼ ìœ íŠœë¸Œ ë§ì´ ë´„â€¦")

    # Diagnose
    total = int(internet_min) + int(phone_min)
    base = base_score_from_minutes(total)
    mult = benchmark_context_multiplier(group, gender, bench_rates)

    # Light well-being adjustment using self inputs (log-driven UX)
    # (This makes the app feel responsive to the userâ€™s data)
    adj = 1.0
    if sleep_hours < 6:
        adj *= 1.05
    if stress >= 8:
        adj *= 1.05
    if mood <= 3:
        adj *= 1.03

    score = int(round(np.clip(base * mult * adj, 0, 100)))
    level = decide_level(score)
    emoji = EMOJI_BY_LEVEL[level]

    st.divider()
    st.subheader(f"{emoji} ì§„ë‹¨ ê²°ê³¼: **{LABEL_KO[level]}**")
    st.metric("ìœ„í—˜ ì ìˆ˜ (0~100)", score)
    st.write(LEVEL_COPY[level])
    st.write(f"ì˜¤ëŠ˜ ë””ì§€í„¸ í™œë™ ì´í•©: **{total}ë¶„**")

    on_m, off_m = switch_off_plan(level, total)
    st.subheader("â±ï¸ ë””ì§€í„¸ ìŠ¤ìœ„ì¹˜ ì˜¤í”„ ì¶”ì²œ")
    st.write(f"ì¶”ì²œ ë£¨í‹´: **{on_m}ë¶„ ì‚¬ìš© â†’ {off_m}ë¶„ ì˜¤í”„** ë°˜ë³µ")
    st.info(DIGITAL_SWITCH_MESSAGES[level])

    # Off window suggestion
    st.subheader("ğŸ•’ ì˜¤ëŠ˜ ì˜¤í”„(OFF) ë¸”ë¡ ì œì•ˆ")
    start_h = st.slider("ì˜¤í”„ ê°€ëŠ¥í•œ ì‹œì‘ ì‹œê°(ì‹œ)", 0, 23, 20)
    end_h = st.slider("ì˜¤í”„ ê°€ëŠ¥í•œ ë ì‹œê°(ì‹œ)", 0, 23, 23)
    st.write(recommend_off_window(level, start_h, end_h))

    st.subheader("ğŸŒ¿ Non-digital activity ì¶”ì²œ")
    for a in recommend_activities(level):
        st.write(f"- {a}")

    # Save log
    st.divider()
    if st.button("ğŸ’¾ ì˜¤ëŠ˜ ê¸°ë¡ ì €ì¥", use_container_width=True):
        new_row = {
            "date": the_date.isoformat(),
            "group": group,
            "gender": gender,
            "internet_min": int(internet_min),
            "phone_min": int(phone_min),
            "sleep_hours": float(sleep_hours),
            "stress_1_10": int(stress),
            "mood_1_10": int(mood),
            "note": note,
        }
        log_df2 = pd.concat([log_df, pd.DataFrame([new_row])], ignore_index=True)
        log_df2 = normalize_log_df(log_df2)

        # Drop duplicates on same date (keep latest)
        log_df2 = log_df2.sort_values("date").drop_duplicates(subset=["date"], keep="last").reset_index(drop=True)
        log_df = log_df2  # update in this run

        saved = safe_save_log(log_df2)
        if saved:
            st.success("ì €ì¥ ì™„ë£Œ! (ë‹¨, Streamlit CloudëŠ” ì €ì¥ì´ íœ˜ë°œë  ìˆ˜ ìˆì–´ìš”. ì•„ë˜ì—ì„œ ë¡œê·¸ ë‹¤ìš´ë¡œë“œë„ í•´ë‘ì„¸ìš”.)")
        else:
            st.warning("ì„œë²„ ì €ì¥ì— ì‹¤íŒ¨í–ˆì–´ìš”. ì•„ë˜ì—ì„œ ë¡œê·¸ë¥¼ ë‹¤ìš´ë¡œë“œí•´ ë³´ê´€í•´ì£¼ì„¸ìš”.")

        st.download_button(
            "â¬‡ï¸ ë‚´ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
            data=log_df2.to_csv(index=False, encoding="utf-8-sig"),
            file_name=LOG_DEFAULT_PATH,
            mime="text/csv",
            use_container_width=True,
        )

    with st.expander("ğŸ” ì ìˆ˜ ê³„ì‚°(íˆ¬ëª…ì„±)"):
        # Show benchmark prevalence for chosen group
        p_i = bench_rates.get(group, {}).get("internet_rate", np.nan)
        p_p = bench_rates.get(group, {}).get("phone_rate", np.nan)
        st.json({
            "total_minutes": total,
            "base_score_from_minutes": base,
            "benchmark_internet_overdep_rate": p_i,
            "benchmark_phone_overdep_rate": p_p,
            "benchmark_multiplier": mult,
            "sleep/stress/mood_adjustment": adj,
            "final_score_0_100": score,
        })


# -----------------------------
# Tab 2: Trend
# -----------------------------
with tabs[1]:
    st.subheader("ğŸ“ˆ ë‚´ ì¶”ì„¸ (ë‚´ ë°ì´í„°ê°€ ìŒ“ì¼ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§)")
    if len(log_df) == 0:
        st.info("ì•„ì§ ì €ì¥ëœ ë¡œê·¸ê°€ ì—†ì–´ìš”. â€˜ì˜¤ëŠ˜ ì§„ë‹¨â€™ì—ì„œ ê¸°ë¡ì„ ì €ì¥í•´ë³´ì„¸ìš” ğŸ™‚")
    else:
        df = log_df.copy()
        df["date_dt"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date_dt"]).sort_values("date_dt")
        df["total_min"] = df["internet_min"].fillna(0) + df["phone_min"].fillna(0)

        # Rolling averages
        df["total_7d_avg"] = df["total_min"].rolling(7, min_periods=1).mean()
        df["total_14d_avg"] = df["total_min"].rolling(14, min_periods=1).mean()

        st.write("ìµœê·¼ ê¸°ë¡:")
        st.dataframe(df[["date", "group", "gender", "internet_min", "phone_min", "total_min", "sleep_hours", "stress_1_10", "mood_1_10", "note"]].tail(14), use_container_width=True)

        st.divider()
        st.write("ì´ ë””ì§€í„¸ ì‹œê°„ ì¶”ì„¸(ë¶„)")

        plt.figure()
        plt.plot(df["date_dt"], df["total_min"], marker="o", label="Total (min)")
        plt.plot(df["date_dt"], df["total_7d_avg"], marker="o", label="7-day avg")
        plt.plot(df["date_dt"], df["total_14d_avg"], marker="o", label="14-day avg")
        plt.xlabel("Date")
        plt.ylabel("Minutes")
        plt.legend()
        st.pyplot(plt.gcf(), clear_figure=True)

        st.write("ì¸í„°ë„·/ìŠ¤ë§ˆíŠ¸í° ë¶„ë¦¬ ì¶”ì„¸(ë¶„)")
        plt.figure()
        plt.plot(df["date_dt"], df["internet_min"], marker="o", label="Internet")
        plt.plot(df["date_dt"], df["phone_min"], marker="o", label="Phone")
        plt.xlabel("Date")
        plt.ylabel("Minutes")
        plt.legend()
        st.pyplot(plt.gcf(), clear_figure=True)

        # Simple insights
        last = df.iloc[-1]
        prev = df.iloc[-2] if len(df) >= 2 else None
        if prev is not None:
            delta = int(last["total_min"] - prev["total_min"])
            arrow = "â¬†ï¸" if delta > 0 else "â¬‡ï¸" if delta < 0 else "â¡ï¸"
            st.info(f"ì „ì¼ ëŒ€ë¹„ ì´ ë””ì§€í„¸ ì‹œê°„: **{arrow} {delta}ë¶„**")


# -----------------------------
# Tab 3: Weekly report
# -----------------------------
with tabs[2]:
    st.subheader("ğŸ—“ï¸ ì£¼ê°„ ë¦¬í¬íŠ¸")
    if len(log_df) == 0:
        st.info("ë¡œê·¸ê°€ ìˆì–´ì•¼ ì£¼ê°„ ë¦¬í¬íŠ¸ê°€ ë‚˜ì™€ìš”. ë¨¼ì € â€˜ì˜¤ëŠ˜ ì§„ë‹¨â€™ì—ì„œ ê¸°ë¡ì„ ì €ì¥í•´ì£¼ì„¸ìš” ğŸ™‚")
    else:
        df = log_df.copy()
        df["date_dt"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date_dt"]).sort_values("date_dt")
        df["total_min"] = df["internet_min"].fillna(0) + df["phone_min"].fillna(0)

        end = df["date_dt"].max()
        start = end - timedelta(days=6)
        week = df[(df["date_dt"] >= start) & (df["date_dt"] <= end)].copy()

        st.write(f"ê¸°ê°„: **{start.date()} ~ {end.date()}**")

        total_sum = int(week["total_min"].sum())
        avg = float(week["total_min"].mean()) if len(week) else 0.0
        max_day = week.loc[week["total_min"].idxmax()] if len(week) else None

        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("ì£¼ê°„ ì´í•©(ë¶„)", total_sum)
        with c2:
            st.metric("ì¼ í‰ê· (ë¶„)", int(round(avg)))
        with c3:
            if max_day is not None:
                st.metric("ìµœëŒ€ ì‚¬ìš©ì¼", f"{max_day['date']} ({int(max_day['total_min'])}ë¶„)")
            else:
                st.metric("ìµœëŒ€ ì‚¬ìš©ì¼", "-")

        st.divider()
        st.write("ì£¼ê°„ ì´ ë””ì§€í„¸ ì‹œê°„(ë¶„)")
        plt.figure()
        plt.plot(week["date_dt"], week["total_min"], marker="o")
        plt.xlabel("Date")
        plt.ylabel("Minutes")
        st.pyplot(plt.gcf(), clear_figure=True)

        # Personalized recommendations based on weekly pattern
        st.subheader("âœ… ë‹¤ìŒ ì£¼ ì•¡ì…˜ í”Œëœ")
        avg_min = avg
        if avg_min >= 360:
            target = int(round(avg_min * 0.8))
            st.write(f"- ë‹¤ìŒ ì£¼ ëª©í‘œ: **ì¼ í‰ê·  {target}ë¶„ ì´í•˜** (ì´ë²ˆ ì£¼ ëŒ€ë¹„ ì•½ 20% ì¤„ì´ê¸°)")
            st.write("- â€˜45ë¶„ ì‚¬ìš© â†’ 20ë¶„ ì˜¤í”„â€™ ë£¨í‹´ì„ ì €ë… ì‹œê°„ì— 2íšŒ ì ìš©í•´ë³´ì„¸ìš”.")
        elif avg_min >= 240:
            target = int(round(avg_min * 0.85))
            st.write(f"- ë‹¤ìŒ ì£¼ ëª©í‘œ: **ì¼ í‰ê·  {target}ë¶„ ì´í•˜** (ì•½ 15% ì¤„ì´ê¸°)")
            st.write("- â€˜60ë¶„ ì‚¬ìš© â†’ 20ë¶„ ì˜¤í”„â€™ ë£¨í‹´ì„ í•˜ë£¨ 2íšŒ ì ìš©í•´ë³´ì„¸ìš”.")
        elif avg_min >= 180:
            target = int(round(avg_min * 0.9))
            st.write(f"- ë‹¤ìŒ ì£¼ ëª©í‘œ: **ì¼ í‰ê·  {target}ë¶„ ì´í•˜** (ì•½ 10% ì¤„ì´ê¸°)")
            st.write("- â€˜90ë¶„ ì‚¬ìš© â†’ 15ë¶„ ì˜¤í”„â€™ ë£¨í‹´ì„ í•˜ë£¨ 1~2íšŒ ì ìš©í•´ë³´ì„¸ìš”.")
        else:
            st.write("- ë‹¤ìŒ ì£¼ ëª©í‘œ: **í˜„ì¬ ìˆ˜ì¤€ ìœ ì§€ + ì˜¤í”„ ìŠµê´€ ìœ ì§€**")
            st.write("- â€˜120ë¶„ ì‚¬ìš© â†’ 10ë¶„ ì˜¤í”„â€™ë¥¼ ìœ ì§€í•´ë³´ì„¸ìš”.")

        st.write("- ì¶”ì²œ ëŒ€ì²´ í™œë™(ìƒìœ„ 3ê°œ):")
        for a in random.sample(NON_DIGITAL_ACTIVITY_POOL, 3):
            st.write(f"  - {a}")


# -----------------------------
# Tab 4: Data admin
# -----------------------------
with tabs[3]:
    st.subheader("âš™ï¸ ë°ì´í„° í™•ì¸ & ë‚´ë³´ë‚´ê¸°")

    with st.expander("ë²¤ì¹˜ë§ˆí¬(ê³µê³µë°ì´í„°) ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(bench_df, use_container_width=True)
        # rates table
        rows = []
        for g, v in bench_rates.items():
            rows.append({
                "êµ¬ë¶„": g,
                "ì¸í„°ë„· ê³¼ì˜ì¡´ ë¹„ìœ¨(ì£¼ì˜+ìœ„í—˜) %": round(v["internet_rate"] * 100, 2),
                "ìŠ¤ë§ˆíŠ¸í° ê³¼ì˜ì¡´ ë¹„ìœ¨(ì£¼ì˜+ìœ„í—˜) %": round(v["phone_rate"] * 100, 2),
            })
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

    st.divider()
    st.write("ë‚´ ë¡œê·¸ ë°ì´í„°")
    if len(log_df) == 0:
        st.info("ì €ì¥ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(log_df, use_container_width=True)

    st.download_button(
        "â¬‡ï¸ ë‚´ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
        data=log_df.to_csv(index=False, encoding="utf-8-sig") if len(log_df) else empty_log_df().to_csv(index=False, encoding="utf-8-sig"),
        file_name=LOG_DEFAULT_PATH,
        mime="text/csv",
        use_container_width=True,
    )

    st.caption("íŒ: Streamlit CloudëŠ” ì„œë²„ ì €ì¥ì´ ì´ˆê¸°í™”ë  ìˆ˜ ìˆìœ¼ë‹ˆ, ë¡œê·¸ CSVëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ ë³´ê´€í•˜ì„¸ìš”.")
